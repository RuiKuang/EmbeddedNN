# **EmbeddedNN**
A collection of works aiming at deploying NN in embedded systems,inspired by 
1. [Neural-Networks-on-Silicon](https://github.com/fengbintu/Neural-Networks-on-Silicon) 
2. [Embedded-Neural-Network](https://github.com/ZhishengWang/Embedded-Neural-Network)
3. [EMDL](https://github.com/csarron/emdl)

## **Mobile Framework**
### **Framework using mobile GPU**

1. [DeepMon: Mobile GPU-based Deep Learning Framework for Continuous Vision Applications](https://nsr.cse.buffalo.edu/mobisys_2017/papers/pdfs/mobisys17-paper07.pdf) [MobiSys '17]
2. [MobiRNN: Efficient Recurrent Neural Network Execution on Mobile GPU](https://arxiv.org/abs/1706.00878) [EMDL '17]
3. Fast and Energy-Efficient CNN Inference on IoT Devices(ucdavis)
4. GPU-based Acceleration of Deep Convolutional Neural Networks on Mobile Platforms(ucdavis)
5. CNNdroid GPU-Accelerated Execution of Trained Deep Convolutional Neural Networks on Android(ucdavis)
6. DeepSense: A GPU-based Deep Convolutional Neural Network Framework on Commodity Mobile Devices

### **Compression**

1. [DeepEye: Resource Efficient Local Execution of Multiple Deep Vision Models using Wearable Commodity Hardware](http://fahim-kawsar.net/papers/Mathur.MobiSys2017-Camera.pdf) [MobiSys '17]
2. DeepX:A Software Accelerator for Low-Power Deep Learning Inference on Mobile Devices(Bell Labs)
3. Sparsification and Separation of Deep Learning Layers for Constrained Resource Inference on Wearables(Bell Labs)
4. Compression of Deep Convolutional  Neural Networks For Fast And Low P ower Mobile Applications(Samsung)

## **Network Compression**
### **Pruning & Sparsity**
1. Learning Structured Sparsity in Deep NeuralNetworks(Pittsburgh)
2. Learning both Weights and Connections for Efficient Neural Networks(stanford)
3. Faster CNNs With Direct Sparse Convolutions and Guided Pruning(intel)
4. Scalpel: Customizing DNN Pruning to the Underlying Hardware Parallelism. (University of Michigan, ARM, ISCA 17)

### **Weight Sharing**
1. Deep Compression:Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding(stanford)

### **Low precision**
1. Ristretto: Hardware-Oriented Approximation of Convolutional Neural Networks(ucdavis)

### **NN Architecture**

1. SqueezedNet:AlexNet-Level Accuracy With 50x Fewer Parameters and '<'0.5MB Model Size(stanford)
2. XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks(Washington)
3. MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications(Google,17)
4. ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices(Face++,17)

## **Code**

1. [ARM Compute Library](https://github.com/ARM-software/ComputeLibrary)
2. [Caffe on ACL](https://github.com/OAID/caffeOnACL)
3. [Microsoft Embedded Learning Library](https://github.com/Microsoft/ELL)












